{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of marianMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlinaZakharova1997/miramedix_practice/blob/main/Copy_of_marianMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkEafHfJ5rEB",
        "outputId": "e2ef83d7-7b13-486e-b982-1b1975adab1c"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 89083, done.\u001b[K\n",
            "remote: Counting objects: 100% (303/303), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 89083 (delta 142), reused 216 (delta 104), pack-reused 88780\u001b[K\n",
            "Receiving objects: 100% (89083/89083), 71.86 MiB | 23.65 MiB/s, done.\n",
            "Resolving deltas: 100% (64131/64131), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1IitckMpMlQ",
        "outputId": "8d092152-7cac-4777-d9de-dcd5e8a465c3"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_Hs3AhYpe4G",
        "outputId": "f2547f6a-a096-4e82-d5fa-e14ee9e93bc2"
      },
      "source": [
        "%cd transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AKFlOmBpg8m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j04t3i3c52qL",
        "outputId": "9bf09fe7-d0cf-4e3b-cda2-b4dbf8b53a83"
      },
      "source": [
        "# %cd transformers # надо установить из сорса, чтобы правильно работало все в папке examples\n",
        "! pip install ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 28.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.3.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.1.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3129886 sha256=fcaba3d91a71166b7a4296eaa739a028853b6dfbcc162d94cd6767b3ffce3b3a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-aockqbfv/wheels/49/62/f4/6730819eed4e6468662b1519bf3bf46419b2335990c77f8767\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rispDM-6uFa",
        "outputId": "4f977617-668c-4030-d9bf-56905f8f7f57"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
            "\u001b[K     |████████████████████████████████| 290 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 41.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.1.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 27.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 48.5 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 48.6 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 53.4 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 datasets-1.15.1 frozenlist-1.2.0 fsspec-2021.11.0 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9Sdn-5zOKGF",
        "outputId": "bf4f4663-80d2-4d38-f9f6-3c3c12b284a9"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeTILUqOfmUN",
        "outputId": "5a927695-79ab-4462-d397-549d985fb17a"
      },
      "source": [
        "!pip install sacrebleu"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▋                            | 10 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 20 kB 30.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 30 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 40 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 90 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2019.12.20)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.4 portalocker-2.3.2 sacrebleu-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrzFszN19JXr"
      },
      "source": [
        "import torch  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR6LnDK-9KOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa310430-b996-4823-bb01-dfc60db7c055"
      },
      "source": [
        "# Определяем на чем у нас будут производиться вычисления (cuda/cpu)\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available else torch.device('cpu')  \n",
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qr6CiKA4dBB",
        "outputId": "9367902e-7ece-4ff9-95ba-a3d9e6f63fdb"
      },
      "source": [
        "!python examples/pytorch/translation/run_translation.py\\\n",
        "    --model_name_or_path Helsinki-NLP/opus-mt-en-de \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --source_lang en \\\n",
        "    --target_lang de \\\n",
        "    --max_source_length=512 \\\n",
        "    --max_target_length=512 \\\n",
        "    --pad_to_max_length True \\\n",
        "    --train_file /content/drive/MyDrive/train_data.json\\\n",
        "    --validation_file /content/drive/MyDrive/val_data.json\\\n",
        "    --output_dir /content/drive/MyDrive/model_output_en_de\\\n",
        "    --per_device_train_batch_size=4 \\\n",
        "    --per_device_eval_batch_size=4 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --predict_with_generate"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/15/2021 20:44:35 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "11/15/2021 20:44:35 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/model_output_en_de/runs/Nov15_20-44-35_15c47c5f577f,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=/content/drive/MyDrive/model_output_en_de,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/model_output_en_de,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "11/15/2021 20:44:36 - WARNING - datasets.builder - Using custom data configuration default-7ae309af3674e040\n",
            "11/15/2021 20:44:36 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-7ae309af3674e040/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-7ae309af3674e040/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n",
            "\r  0% 0/2 [00:00<?, ?it/s]\r100% 2/2 [00:00<00:00, 2357.68it/s]\n",
            "11/15/2021 20:44:36 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
            "11/15/2021 20:44:37 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
            "100% 2/2 [00:00<00:00, 109.39it/s]\n",
            "11/15/2021 20:44:37 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "11/15/2021 20:44:37 - INFO - datasets.builder - Generating split train\n",
            "11/15/2021 20:44:37 - INFO - datasets.builder - Generating split validation\n",
            "11/15/2021 20:44:37 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7ae309af3674e040/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 304.40it/s]\n",
            "[INFO|file_utils.py:1753] 2021-11-15 20:44:38,035 >> https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpvc3becm4\n",
            "Downloading: 100% 1.30k/1.30k [00:00<00:00, 1.19MB/s]\n",
            "[INFO|file_utils.py:1757] 2021-11-15 20:44:38,165 >> storing https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/2a8c1eaa4a24e7d8310cf13b624ffd50ced031f97fcd5095795e5a93de1f6d26.5ec8fb24b2bb449c39e4ddc9f2a74705d02174497d88ab7e14a0459482777b32\n",
            "[INFO|file_utils.py:1765] 2021-11-15 20:44:38,165 >> creating metadata file for /root/.cache/huggingface/transformers/2a8c1eaa4a24e7d8310cf13b624ffd50ced031f97fcd5095795e5a93de1f6d26.5ec8fb24b2bb449c39e4ddc9f2a74705d02174497d88ab7e14a0459482777b32\n",
            "[INFO|configuration_utils.py:588] 2021-11-15 20:44:38,165 >> loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/2a8c1eaa4a24e7d8310cf13b624ffd50ced031f97fcd5095795e5a93de1f6d26.5ec8fb24b2bb449c39e4ddc9f2a74705d02174497d88ab7e14a0459482777b32\n",
            "[INFO|configuration_utils.py:625] 2021-11-15 20:44:38,167 >> Model config MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-de\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      58100\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 58100,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 58100,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 58101\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1753] 2021-11-15 20:44:38,310 >> https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp43isjcxr\n",
            "Downloading: 100% 42.0/42.0 [00:00<00:00, 49.2kB/s]\n",
            "[INFO|file_utils.py:1757] 2021-11-15 20:44:38,450 >> storing https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/f87290e6189c52fe526059b9ff4268f6078e91dc00f897dc1069ef9e523cfb10.7cb22b2c61cbcf12daddcee96423e3647a351804338e4fe8841b32c12bbca4f1\n",
            "[INFO|file_utils.py:1765] 2021-11-15 20:44:38,450 >> creating metadata file for /root/.cache/huggingface/transformers/f87290e6189c52fe526059b9ff4268f6078e91dc00f897dc1069ef9e523cfb10.7cb22b2c61cbcf12daddcee96423e3647a351804338e4fe8841b32c12bbca4f1\n",
            "[INFO|configuration_utils.py:588] 2021-11-15 20:44:38,579 >> loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/2a8c1eaa4a24e7d8310cf13b624ffd50ced031f97fcd5095795e5a93de1f6d26.5ec8fb24b2bb449c39e4ddc9f2a74705d02174497d88ab7e14a0459482777b32\n",
            "[INFO|configuration_utils.py:625] 2021-11-15 20:44:38,580 >> Model config MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-de\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      58100\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 58100,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 58100,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 58101\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1753] 2021-11-15 20:44:38,901 >> https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/source.spm not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpq9xz6lck\n",
            "Downloading: 100% 750k/750k [00:00<00:00, 4.85MB/s]\n",
            "[INFO|file_utils.py:1757] 2021-11-15 20:44:39,206 >> storing https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/source.spm in cache at /root/.cache/huggingface/transformers/0a566b81a8379ce1ba28429c9313e7eb2fa87eea3649415c7d88479d27926916.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\n",
            "[INFO|file_utils.py:1765] 2021-11-15 20:44:39,206 >> creating metadata file for /root/.cache/huggingface/transformers/0a566b81a8379ce1ba28429c9313e7eb2fa87eea3649415c7d88479d27926916.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\n",
            "[INFO|file_utils.py:1753] 2021-11-15 20:44:39,334 >> https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/target.spm not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmplo35fmu2\n",
            "Downloading: 100% 778k/778k [00:00<00:00, 5.13MB/s]\n",
            "[INFO|file_utils.py:1757] 2021-11-15 20:44:39,639 >> storing https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/target.spm in cache at /root/.cache/huggingface/transformers/fca0ee25c85807e95d28fd8b051a7202783846dd34847e2b0496a6a7f86ff5c2.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\n",
            "[INFO|file_utils.py:1765] 2021-11-15 20:44:39,640 >> creating metadata file for /root/.cache/huggingface/transformers/fca0ee25c85807e95d28fd8b051a7202783846dd34847e2b0496a6a7f86ff5c2.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\n",
            "[INFO|file_utils.py:1753] 2021-11-15 20:44:39,774 >> https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpr3nkel6h\n",
            "Downloading: 100% 1.21M/1.21M [00:00<00:00, 7.24MB/s]\n",
            "[INFO|file_utils.py:1757] 2021-11-15 20:44:40,091 >> storing https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/5ced037333c7bfbd5bde557944ea2909dc59f734d08977e633a0b733a2d43dca.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\n",
            "[INFO|file_utils.py:1765] 2021-11-15 20:44:40,091 >> creating metadata file for /root/.cache/huggingface/transformers/5ced037333c7bfbd5bde557944ea2909dc59f734d08977e633a0b733a2d43dca.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-15 20:44:40,633 >> loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/source.spm from cache at /root/.cache/huggingface/transformers/0a566b81a8379ce1ba28429c9313e7eb2fa87eea3649415c7d88479d27926916.5ff349d0044d463eca29fbb3a3d21a2dd0511ced746d6c6941daa893faf53d79\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-15 20:44:40,634 >> loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/target.spm from cache at /root/.cache/huggingface/transformers/fca0ee25c85807e95d28fd8b051a7202783846dd34847e2b0496a6a7f86ff5c2.7bc2908774e59068751778d82930d24fe5b81375f4e06aa8f2a62298103c9587\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-15 20:44:40,634 >> loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/5ced037333c7bfbd5bde557944ea2909dc59f734d08977e633a0b733a2d43dca.fe9bdbcb654d47ed6918ebaad81166b879fd0bc12ea76a2cc54359202fa854d7\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-15 20:44:40,634 >> loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f87290e6189c52fe526059b9ff4268f6078e91dc00f897dc1069ef9e523cfb10.7cb22b2c61cbcf12daddcee96423e3647a351804338e4fe8841b32c12bbca4f1\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-15 20:44:40,634 >> loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-15 20:44:40,634 >> loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1742] 2021-11-15 20:44:40,634 >> loading file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/tokenizer.json from cache at None\n",
            "[INFO|configuration_utils.py:588] 2021-11-15 20:44:40,770 >> loading configuration file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/2a8c1eaa4a24e7d8310cf13b624ffd50ced031f97fcd5095795e5a93de1f6d26.5ec8fb24b2bb449c39e4ddc9f2a74705d02174497d88ab7e14a0459482777b32\n",
            "[INFO|configuration_utils.py:625] 2021-11-15 20:44:40,771 >> Model config MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-de\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      58100\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 58100,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 58100,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.13.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 58101\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1753] 2021-11-15 20:44:41,095 >> https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwh3wz5vd\n",
            "Downloading: 100% 284M/284M [00:07<00:00, 38.5MB/s]\n",
            "[INFO|file_utils.py:1757] 2021-11-15 20:44:48,939 >> storing https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/b85bfb33344be279530e951bbc145ecac4b21e7aa9bba8291a2cb6e2935a028f.22da5f3358559cc749275f8f361ed77da760b190db01e435fda67fecbb70b82d\n",
            "[INFO|file_utils.py:1765] 2021-11-15 20:44:48,939 >> creating metadata file for /root/.cache/huggingface/transformers/b85bfb33344be279530e951bbc145ecac4b21e7aa9bba8291a2cb6e2935a028f.22da5f3358559cc749275f8f361ed77da760b190db01e435fda67fecbb70b82d\n",
            "[INFO|modeling_utils.py:1342] 2021-11-15 20:44:48,939 >> loading weights file https://huggingface.co/Helsinki-NLP/opus-mt-en-de/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/b85bfb33344be279530e951bbc145ecac4b21e7aa9bba8291a2cb6e2935a028f.22da5f3358559cc749275f8f361ed77da760b190db01e435fda67fecbb70b82d\n",
            "[INFO|modeling_utils.py:1609] 2021-11-15 20:44:51,717 >> All model checkpoint weights were used when initializing MarianMTModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1618] 2021-11-15 20:44:51,717 >> All the weights of MarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-de.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n",
            "Running tokenizer on train dataset:   0% 0/6 [00:00<?, ?ba/s]11/15/2021 20:44:55 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7ae309af3674e040/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-4ad5413b46449a15.arrow\n",
            "Running tokenizer on train dataset: 100% 6/6 [00:14<00:00,  2.46s/ba]\n",
            "Running tokenizer on validation dataset:   0% 0/3 [00:00<?, ?ba/s]11/15/2021 20:45:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7ae309af3674e040/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-fc96975e7ddd3ce6.arrow\n",
            "Running tokenizer on validation dataset: 100% 3/3 [00:04<00:00,  1.55s/ba]\n",
            "11/15/2021 20:45:12 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.15.1/metrics/sacrebleu/sacrebleu.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpstnjzjkj\n",
            "Downloading: 5.67kB [00:00, 6.50MB/s]       \n",
            "11/15/2021 20:45:12 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.15.1/metrics/sacrebleu/sacrebleu.py in cache at /root/.cache/huggingface/datasets/downloads/36bfa4c44bd6400f2406fc7bb159628d599c8d75f468e4833e57022fd3c580cd.c963034e2d53140c7fb735578a73ea2c2eec8a5543784d5c1d4d7af73dde52d5.py\n",
            "11/15/2021 20:45:12 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/36bfa4c44bd6400f2406fc7bb159628d599c8d75f468e4833e57022fd3c580cd.c963034e2d53140c7fb735578a73ea2c2eec8a5543784d5c1d4d7af73dde52d5.py\n",
            "[INFO|trainer.py:1196] 2021-11-15 20:45:32,515 >> ***** Running training *****\n",
            "[INFO|trainer.py:1197] 2021-11-15 20:45:32,516 >>   Num examples = 5211\n",
            "[INFO|trainer.py:1198] 2021-11-15 20:45:32,516 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1199] 2021-11-15 20:45:32,516 >>   Instantaneous batch size per device = 4\n",
            "[INFO|trainer.py:1200] 2021-11-15 20:45:32,516 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:1201] 2021-11-15 20:45:32,516 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1202] 2021-11-15 20:45:32,516 >>   Total optimization steps = 3909\n",
            "{'loss': 2.6273, 'learning_rate': 4.360450243028908e-05, 'epoch': 0.38}\n",
            " 13% 500/3909 [06:50<46:08,  1.23it/s][INFO|trainer.py:1995] 2021-11-15 20:52:22,767 >> Saving model checkpoint to /content/drive/MyDrive/model_output_en_de/checkpoint-500\n",
            "[INFO|configuration_utils.py:417] 2021-11-15 20:52:23,242 >> Configuration saved in /content/drive/MyDrive/model_output_en_de/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-15 20:52:38,651 >> Model weights saved in /content/drive/MyDrive/model_output_en_de/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-15 20:52:38,841 >> tokenizer config file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-15 20:52:39,067 >> Special tokens file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 2.3755, 'learning_rate': 3.7209004860578156e-05, 'epoch': 0.77}\n",
            " 26% 1000/3909 [14:25<39:27,  1.23it/s][INFO|trainer.py:1995] 2021-11-15 20:59:57,821 >> Saving model checkpoint to /content/drive/MyDrive/model_output_en_de/checkpoint-1000\n",
            "[INFO|configuration_utils.py:417] 2021-11-15 20:59:57,827 >> Configuration saved in /content/drive/MyDrive/model_output_en_de/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-15 21:00:04,490 >> Model weights saved in /content/drive/MyDrive/model_output_en_de/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-15 21:00:04,496 >> tokenizer config file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-15 21:00:04,500 >> Special tokens file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 2.1927, 'learning_rate': 3.0813507290867236e-05, 'epoch': 1.15}\n",
            " 38% 1500/3909 [21:33<32:47,  1.22it/s][INFO|trainer.py:1995] 2021-11-15 21:07:06,681 >> Saving model checkpoint to /content/drive/MyDrive/model_output_en_de/checkpoint-1500\n",
            "[INFO|configuration_utils.py:417] 2021-11-15 21:07:06,687 >> Configuration saved in /content/drive/MyDrive/model_output_en_de/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-15 21:07:10,841 >> Model weights saved in /content/drive/MyDrive/model_output_en_de/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-15 21:07:10,871 >> tokenizer config file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-15 21:07:10,875 >> Special tokens file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-1500/special_tokens_map.json\n",
            "{'loss': 1.9905, 'learning_rate': 2.4418009721156306e-05, 'epoch': 1.53}\n",
            " 51% 2000/3909 [28:43<25:53,  1.23it/s][INFO|trainer.py:1995] 2021-11-15 21:14:15,939 >> Saving model checkpoint to /content/drive/MyDrive/model_output_en_de/checkpoint-2000\n",
            "[INFO|configuration_utils.py:417] 2021-11-15 21:14:15,945 >> Configuration saved in /content/drive/MyDrive/model_output_en_de/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-15 21:14:19,819 >> Model weights saved in /content/drive/MyDrive/model_output_en_de/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-15 21:14:19,824 >> tokenizer config file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-15 21:14:19,829 >> Special tokens file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-2000/special_tokens_map.json\n",
            "{'loss': 1.9672, 'learning_rate': 1.8022512151445383e-05, 'epoch': 1.92}\n",
            " 64% 2500/3909 [35:51<18:59,  1.24it/s][INFO|trainer.py:1995] 2021-11-15 21:21:24,141 >> Saving model checkpoint to /content/drive/MyDrive/model_output_en_de/checkpoint-2500\n",
            "[INFO|configuration_utils.py:417] 2021-11-15 21:21:24,147 >> Configuration saved in /content/drive/MyDrive/model_output_en_de/checkpoint-2500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-15 21:21:28,491 >> Model weights saved in /content/drive/MyDrive/model_output_en_de/checkpoint-2500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-15 21:21:28,497 >> tokenizer config file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-15 21:21:28,502 >> Special tokens file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-2500/special_tokens_map.json\n",
            "{'loss': 1.841, 'learning_rate': 1.162701458173446e-05, 'epoch': 2.3}\n",
            " 77% 3000/3909 [43:02<12:18,  1.23it/s][INFO|trainer.py:1995] 2021-11-15 21:28:35,580 >> Saving model checkpoint to /content/drive/MyDrive/model_output_en_de/checkpoint-3000\n",
            "[INFO|configuration_utils.py:417] 2021-11-15 21:28:35,586 >> Configuration saved in /content/drive/MyDrive/model_output_en_de/checkpoint-3000/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-15 21:28:40,024 >> Model weights saved in /content/drive/MyDrive/model_output_en_de/checkpoint-3000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-15 21:28:40,031 >> tokenizer config file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-15 21:28:40,036 >> Special tokens file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-3000/special_tokens_map.json\n",
            "{'loss': 1.8011, 'learning_rate': 5.231517012023536e-06, 'epoch': 2.69}\n",
            " 90% 3500/3909 [50:10<05:33,  1.23it/s][INFO|trainer.py:1995] 2021-11-15 21:35:43,199 >> Saving model checkpoint to /content/drive/MyDrive/model_output_en_de/checkpoint-3500\n",
            "[INFO|configuration_utils.py:417] 2021-11-15 21:35:43,204 >> Configuration saved in /content/drive/MyDrive/model_output_en_de/checkpoint-3500/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-15 21:35:47,430 >> Model weights saved in /content/drive/MyDrive/model_output_en_de/checkpoint-3500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-15 21:35:47,436 >> tokenizer config file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-3500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-15 21:35:47,441 >> Special tokens file saved in /content/drive/MyDrive/model_output_en_de/checkpoint-3500/special_tokens_map.json\n",
            "100% 3909/3909 [56:03<00:00,  1.31it/s][INFO|trainer.py:1409] 2021-11-15 21:41:36,176 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 3363.6598, 'train_samples_per_second': 4.648, 'train_steps_per_second': 1.162, 'train_loss': 2.077282390072389, 'epoch': 3.0}\n",
            "100% 3909/3909 [56:03<00:00,  1.16it/s]\n",
            "[INFO|trainer.py:1995] 2021-11-15 21:41:36,191 >> Saving model checkpoint to /content/drive/MyDrive/model_output_en_de\n",
            "[INFO|configuration_utils.py:417] 2021-11-15 21:41:36,198 >> Configuration saved in /content/drive/MyDrive/model_output_en_de/config.json\n",
            "[INFO|modeling_utils.py:1060] 2021-11-15 21:41:40,270 >> Model weights saved in /content/drive/MyDrive/model_output_en_de/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2037] 2021-11-15 21:41:40,276 >> tokenizer config file saved in /content/drive/MyDrive/model_output_en_de/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2043] 2021-11-15 21:41:40,282 >> Special tokens file saved in /content/drive/MyDrive/model_output_en_de/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     2.0773\n",
            "  train_runtime            = 0:56:03.65\n",
            "  train_samples            =       5211\n",
            "  train_samples_per_second =      4.648\n",
            "  train_steps_per_second   =      1.162\n",
            "11/15/2021 21:41:40 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:2243] 2021-11-15 21:41:40,448 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2245] 2021-11-15 21:41:40,448 >>   Num examples = 2602\n",
            "[INFO|trainer.py:2248] 2021-11-15 21:41:40,448 >>   Batch size = 4\n",
            "100% 651/651 [32:26<00:00,  4.55s/it]11/15/2021 22:14:44 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/sacrebleu/default/default_experiment-1-0.arrow\n",
            "100% 651/651 [33:00<00:00,  3.04s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_bleu               =    33.9121\n",
            "  eval_gen_len            =    76.8132\n",
            "  eval_loss               =     1.1298\n",
            "  eval_runtime            = 0:33:03.60\n",
            "  eval_samples            =       2602\n",
            "  eval_samples_per_second =      1.312\n",
            "  eval_steps_per_second   =      0.328\n",
            "[INFO|modelcard.py:449] 2021-11-15 22:14:44,276 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 33.9121}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxZa5_KBD-3G",
        "outputId": "c79ebe44-860a-4405-ec6b-61c83119b759"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}